# -*- coding: utf-8 -*-
"""AML_Group_MM08_Miniproject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OOQgPlnpRPD5iyX2MaoU1p5Mjsk0BM5x

## AML Mini-Project 
### Group MM_08: 
### 1032180678 Ajinkya Karnik
### 1032180007 Sumedh Kamble
### 1032180268 Chirantan Joshi
### 1032180715 Dhwanit Kapur
"""

# Commented out IPython magic to ensure Python compatibility.
#importing lib
import os
import cv2
import random
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
import matplotlib.pyplot as plt
# %matplotlib inline

#importing dataset 
data_path = "dataset"
num_classes = 2
num_samples = 1200
row_orig = 100
col_orig = 100

# method to load image data into numpy array
def load_data():
    labels = os.listdir(data_path)
    print(labels[:])
    num_labels = len(labels)
    
    X = np.ndarray((num_samples,(row_orig*col_orig*3)),dtype=np.uint8)
    y = np.zeros((num_samples,),dtype=np.uint8)
    i=0
    j=0
    for label in labels:
        imgs_name_data = os.listdir(os.path.join(data_path,label))
        total_imgs = len(imgs_name_data)
        print(label,total_imgs)
        count=0
        for img_name in imgs_name_data:
            img = cv2.imread(os.path.join(data_path,label,img_name),cv2.IMREAD_COLOR)
            img = cv2.resize(img,(100,100))
            img = np.array([img])
            img = np.reshape(img,((row_orig*col_orig*3),))
            X[i] = img
            y[i] = j
            i = i + 1
            count = count + 1
            if(i%100==0):
                print("{0}/{1} images loaded".format(count,total_imgs))
        j = j + 1
    print("All images are loaded")
    np.save("data.npy",X,y)
    return X,y

# calling the method to load data in the form of numpy array
X,y = load_data()

# shape of loaded data
print("X : {}".format(X.shape)) # O/P  : X : (1200, 30000)
print("y : {}".format(y.shape)) # O/P  : y : (1200,)

X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.80,test_size=0.20,shuffle=True,random_state=42)
print("X_train : {}".format(X_train.shape))
print("y_train : {}".format(y_train.shape))
print("X_test : {}".format(X_test.shape))
print("y_test : {}".format(y_test.shape))

# showing first 5 images
plt.figure(figsize=(10,4))
for index,(image,label) in enumerate(zip(X_train[0:5],y_train[0:5])):
    plt.subplot(1,5,index+1)
    plt.imshow(np.reshape(image,(100,100,3)))
    plt.title('Label %d'%label,fontsize=20)
    plt.plot()

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# importing stats to finding z-score 
from scipy import stats
from scipy.stats import norm
import math

X = stats.zscore(X_train,axis=1)

# Fit a normal distribution to the data:
mu, variance = norm.fit(X)

# Plot the PDF.
sigma = math.sqrt(variance)
x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)
plt.plot(x, stats.norm.pdf(x, mu, sigma))
plt.show()

"""

---


### Random Forest"""

rf = RandomForestClassifier()
rf.fit(X_train,y_train)

pred = rf.predict(X_test)
pred

#Randomforest accuracy
print(f'Train Accuracy:- {rf.score(X_train,y_train):.3f}')
print(f'Test Accuracy:- {rf.score(X_test,y_test):.3f}')

#Confusion Matrix
print(confusion_matrix(y_test,pred))

#Classification Report
target_names = ['class 0(Parasitized)', 'class 1(Uninfected)']
print(classification_report(y_test, pred, target_names=target_names))

"""### Random Forest with Hyper Parameters"""

#Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 10, stop = 150, num = 10)]
#Number of features to consider at every split
max_features = ['auto','sqrt']
#Maximum number of levels in tree
max_depth = [2,4]
#Minimum no of sample required to split a node
min_samples_split = [2,5]
#Minimum number of samples rewuired at each leaf node
min_samples_leaf = [1,2]
#Meathod of selecting samples for training each tree
bootstrap = [True,False]

#Create a parameter grid
param_grid = {'n_estimators': n_estimators,
              'max_features': max_features,
              'max_depth': max_depth,
              'min_samples_split': min_samples_split,
              'min_samples_leaf': min_samples_leaf,
              'bootstrap': bootstrap}
print(param_grid)

from sklearn.model_selection import GridSearchCV
rf_grid = GridSearchCV(estimator= rf, param_grid= param_grid, cv=5, verbose=2, n_jobs=4)

brfm = rf_grid.fit(X_train, y_train)

#best parameters for model
rf_grid.best_params_

#Random Forest after hypertuning
print(f'Train Accuracy:- {rf_grid.score(X_train,y_train):.3f}')
print(f'Test Accuracy:- {rf_grid.score(X_test,y_test):.3f}')

#Confusion Matrix
print(confusion_matrix(y_test,brfm.predict(X_test)))

xpred = brfm.predict(X_test)

#Classification Report
target_names = ['class 0(Parasitized)', 'class 1(Uninfected)']
print(classification_report(y_test, xpred, target_names=target_names))

#total no of decision trees in random forest
len(brfm.best_estimator_)

#printing info about 100 
brfm.best_estimator_

#Plotting one decision tree
plt.figure(figsize=(150,100))
tree.plot_tree(brfm.best_estimator_[1],filled=True)

#Plotting one decision tree
plt.figure(figsize=(150,100))
tree.plot_tree(rf.estimators_[1],filled=True)

"""### Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)

y_pred = nb.predict(X_test)
print(y_pred)

print(f'Train Accuracy:- {nb.score(X_train,y_train):.3f}')
print(f'Test Accuracy:- {nb.score(X_test,y_test):.3f}')

#Confusion Matrix
print(confusion_matrix(y_test,y_pred))

#Classification Report
target_names = ['class 0(Parasitized)', 'class 1(Uninfected)']
print(classification_report(y_test, y_pred, target_names=target_names))

"""### Logistic Regression """

# creating the logistic regression object
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(max_iter=1000)

# training the model and performing the prediction on test set
lr.fit(X_train,y_train)
lr_pred = lr.predict(X_test)
lr_pred.shape

# printing the accuracy of model on test set
print("Train : {}".format(lr.score(X_train,y_train)))
print("Test : {}".format(lr.score(X_test,y_test)))

#Confusion Matrix
print(confusion_matrix(y_test,lr_pred))

#Classification Report
target_names = ['class 0(Parasitized)', 'class 1(Uninfected)']
print(classification_report(y_test, lr_pred, target_names=target_names))

"""### SVM"""

from sklearn.svm import LinearSVC, SVC
from sklearn import metrics
from sklearn.metrics import confusion_matrix

def report(model, X_train, X_test, y_train, y_test, name):
    model.fit(X_train, y_train)
    accuracy     = model.score(X_test, y_test)
    y_pred = model.predict(X_test)

    df_model = pd.DataFrame({'Model'        : [name],
                             'Accuracy'     : [accuracy],
                            })  
    return df_model

svc = SVC(kernel='rbf', probability=True)
linearsvc = LinearSVC()
polysvc = SVC(kernel='poly')
df_models = pd.concat([report(linearsvc, X_train, X_test, y_train, y_test, 'LinearSVC'),
                       report(polysvc, X_train, X_test, y_train, y_test, 'PolyKernelSVC'),
                       report(svc, X_train, X_test, y_train, y_test, 'RBFSVC')
                       ], axis=0).reset_index()
df_models = df_models.drop('index', axis=1)
print('Performance of All models: \n',df_models.loc[:,['Model','Accuracy']])

svmpred = svc.predict(X_test)

print(svmpred)

# printing the accuracy of model on test set
print("Train : {}".format(svc.score(X_train,y_train)))
print("Test : {}".format(svc.score(X_test,y_test)))

#Confusion Matrix
print(confusion_matrix(y_test,svmpred))

#Classification Report
target_names = ['class 0(Parasitized)', 'class 1(Uninfected)']
print(classification_report(y_test, svmpred, target_names=target_names))

"""### Ensemble"""

from sklearn.ensemble import VotingClassifier

model = VotingClassifier(estimators=[('rf', rf), ('nb', nb), ('svm', svc)], voting='hard')
model.fit(X_train,y_train)
model.score(X_test,y_test)

# printing the accuracy of model on test set
print("Train : {}".format(model.score(X_train,y_train)))
print("Test : {}".format(model.score(X_test,y_test)))

pred1 = rf.predict_proba(X_test)
pred2 = nb.predict_proba(X_test)
pred3 = svc.predict_proba(X_test)

finalpred = (pred1+pred2+pred3)/3

print(finalpred)

print(finalpred[:,0])
finalpred = finalpred[:,0]

for i in range (0,len(finalpred)):
    if(finalpred[i]>=0.5):
        finalpred[i] = 0
    else:
        finalpred[i] = 1
        
finalpred = finalpred.astype("int32")
print(finalpred)

s = y_test
count = 0
for i in range(len(finalpred)):
  if finalpred[i]==s[i]:
    count = count+1
print(count)
len(finalpred)
accuracy = count/len(finalpred)
accuracy

#Confusion Matrix
print(confusion_matrix(y_test,finalpred))

#Classification Report
target_names = ['class 0(Parasitized)', 'class 1(Uninfected)']
print(classification_report(y_test, finalpred, target_names=target_names))

